{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "# **Spam Email Classification**\n",
    "\n",
    "There are various supervised learning algorithms that can be used for classification problems. One of the applications of these learning algorithms is classifying spam emails. Here, various learning algorithms such as Decision tree, Random forest, SVC, Logistic Regression and MLP are used to classify the mails and their results are compared. The email data used for the analysis is obtained from the spamassassin website (https://spamassassin.apache.org/old/publiccorpus/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "## Downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import tarfile\n",
    "\n",
    "# function to download dataset from the spam corpus using URLs\n",
    "def download_file(url, folderPath):\n",
    "    filename = url.split('/')[-1]\n",
    "\n",
    "    if not os.path.isdir(folderPath):\n",
    "        os.makedirs(folderPath)\n",
    "         \n",
    "    filepath, headers = urlretrieve(url, os.path.join(folderPath, filename))\n",
    "    return filepath\n",
    "\n",
    "def extract_file(filepath, extractionPath):\n",
    "    tar = tarfile.open(filepath)\n",
    "    folderPath = os.path.join(extractionPath, filepath.split('/')[-1].split('.')[0])\n",
    "    tar.extractall(folderPath)\n",
    "    return folderPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "## Preprocessing and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "\n",
    "def get_processed_msg(message_orig):\n",
    "    \"\"\"\n",
    "    function to preprocess the email message body to remove unnecessary content\n",
    "    \n",
    "    Arguments:\n",
    "    message_orig -- raw text content of the email body\n",
    "    \n",
    "    Returns:\n",
    "    message -- email body after processing the text contents\n",
    "    \"\"\"\n",
    "    \n",
    "    message = copy.deepcopy(message_orig)\n",
    "    \n",
    "    # remove white space\n",
    "    message = message.replace(\"\\n\", \" \")\n",
    "    \n",
    "    # change the texts to lower case\n",
    "    message = message.lower()\n",
    "    \n",
    "    # remove html tags and parse them\n",
    "    message = re.sub(r\"<(“[^”]*”|'[^’]*’|[^'”>])*>\", \" \", message)\n",
    "    \n",
    "    # replace emails with 'email'\n",
    "    message = re.sub(r\"[\\S]+@[\\S]+\\.[\\S]+\", \"EMAIL\", message)\n",
    "    \n",
    "    # replace URLs with 'url'\n",
    "    message = re.sub(r\"http[s]?://[\\S]+\", \"URL\", message)\n",
    "    \n",
    "    # replace the currency symbols with 'currency'\n",
    "    message = re.sub(r\"\\$([ ]?(\\d)+)?\", \"AMOUNT\", message)\n",
    "    \n",
    "    # replace numbers with 'number'\n",
    "    message = re.sub(r\"\\b(\\d)+\\b\", \"NUMBER\", message)\n",
    "    \n",
    "    # remove unnecessary punctuations and special characters\n",
    "    message = re.sub(r\"[!@#$%^&*()_+\\-=\\[\\]{};`~':\\\"\\\\|,.<>\\/?]+\", \" \", message)\n",
    "    \n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import email\n",
    "\n",
    "def get_mail_contents(folderPath):\n",
    "    \"\"\"\n",
    "    function to fetch the message text contents from list of emails\n",
    "    \n",
    "    Arguments:\n",
    "    mail_type -- type of email data to be fetched - spam/ham\n",
    "    \n",
    "    Returns:\n",
    "    messages -- an array of text content from body of list of emails\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = []\n",
    "    mailList = glob.glob(folderPath + \"/*/*\", recursive = True)\n",
    "    for email_file in mailList:\n",
    "        message = \"\"\n",
    "        try:\n",
    "            fp = open(email_file, encoding= 'latin-1')\n",
    "            email_content = email.message_from_file(fp)\n",
    "            for part in email_content.walk():\n",
    "                if part.get_content_type() == 'text/plain':\n",
    "                    message = part.get_payload()\n",
    "        except:\n",
    "            print(\"Error in parsing document %r\" % email_file)\n",
    "        messages.append(get_processed_msg(message))\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# creating features using the 5000 most frequently found words in the mail dataset\n",
    "def get_frequent_words(messages, featureCount = 5000):\n",
    "    vectorizer = CountVectorizer(stop_words = 'english', max_features = featureCount)\n",
    "    vectorizer.fit(messages)\n",
    "    frequentWords = vectorizer.get_feature_names_out()\n",
    "    return frequentWords\n",
    "\n",
    "def extract_features(messages, wordList):\n",
    "    vectorizer = CountVectorizer(vocabulary=wordList)\n",
    "    X = vectorizer.fit_transform(messages).toarray()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_messages(url):\n",
    "    downloadPath = os.path.join(\"dataset\")\n",
    "    extractionPath = os.path.join(downloadPath, \"extracted\")\n",
    "    \n",
    "    filePath = download_file(url, downloadPath)\n",
    "    folderPath = extract_file(filePath, extractionPath)\n",
    "    messages = get_mail_contents(folderPath)\n",
    "    \n",
    "    return messages\n",
    "\n",
    "def load_dataset(urls, testSize, featureCount):\n",
    "    \n",
    "    messages = []\n",
    "    \n",
    "    for url in urls[\"spam\"]:\n",
    "        messages.extend(get_messages(url))\n",
    "        \n",
    "    spamCount = len(messages)\n",
    "    \n",
    "    for url in urls[\"ham\"]:\n",
    "        messages.extend(get_messages(url))\n",
    "    \n",
    "    hamCount = len(messages) - spamCount\n",
    "    \n",
    "    y = np.concatenate((np.ones((spamCount)), np.zeros((hamCount))))\n",
    "    \n",
    "    train_messages, test_messages, train_y, test_y = train_test_split(messages, y, test_size=testSize, random_state = 4)\n",
    "       \n",
    "    vocabulary = get_frequent_words(train_messages, featureCount)\n",
    "    \n",
    "    train_X = extract_features(train_messages, vocabulary)\n",
    "    test_X = extract_features(test_messages, vocabulary)\n",
    "    \n",
    "    return train_X, test_X, train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def display_classifier_metrics(classifier, y_actual, y_pred):\n",
    "    print(\"\\n\\n\", classifier)\n",
    "    print(\"Confusion matrics : \", confusion_matrix(y_actual, y_pred))\n",
    "    print(\"Precision : \", precision_score(y_actual, y_pred))\n",
    "    print(\"Recall : \", recall_score(y_actual, y_pred))\n",
    "    print(\"F1 score : \", f1_score(y_actual, y_pred))\n",
    "    print(\"Accuracy score : \", accuracy_score(y_actual, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "## Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import os\n",
    "\n",
    "urls = {'spam': [\"https://spamassassin.apache.org/old/publiccorpus/20021010_spam.tar.bz2\", \"https://spamassassin.apache.org/old/publiccorpus/20030228_spam.tar.bz2\", \"https://spamassassin.apache.org/old/publiccorpus/20030228_spam_2.tar.bz2\", \"https://spamassassin.apache.org/old/publiccorpus/20050311_spam_2.tar.bz2\"],\n",
    "        'ham': [\"https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2\", \"https://spamassassin.apache.org/old/publiccorpus/20021010_hard_ham.tar.bz2\", \"https://spamassassin.apache.org/old/publiccorpus/20030228_easy_ham.tar.bz2\", \"https://spamassassin.apache.org/old/publiccorpus/20030228_easy_ham_2.tar.bz2\",\"https://spamassassin.apache.org/old/publiccorpus/20030228_hard_ham.tar.bz2\"]}\n",
    "test_size = 0.33\n",
    "featureCount = 5000 \n",
    "\n",
    "X_train, X_test, y_train, y_test = load_dataset(urls, test_size, featureCount)\n",
    "\n",
    "classifiers = {\n",
    "    'svc' : SVC(),\n",
    "    'decision tree' : DecisionTreeClassifier(),\n",
    "    'random forest' : RandomForestClassifier(),\n",
    "    'logistic regression' : LogisticRegression(solver = 'newton-cg'),\n",
    "    'mlp' : MLPClassifier()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " svc\n",
      "Confusion matrics :  [[2284   21]\n",
      " [ 728  515]]\n",
      "Precision :  0.960820895522388\n",
      "Recall :  0.414320193081255\n",
      "F1 score :  0.5789769533445756\n",
      "Accuracy score :  0.7888951521984217\n",
      "\n",
      "\n",
      " decision tree\n",
      "Confusion matrics :  [[2148  157]\n",
      " [  19 1224]]\n",
      "Precision :  0.8863142650253439\n",
      "Recall :  0.9847144006436042\n",
      "F1 score :  0.9329268292682927\n",
      "Accuracy score :  0.9503945885005637\n",
      "\n",
      "\n",
      " random forest\n",
      "Confusion matrics :  [[2200  105]\n",
      " [  23 1220]]\n",
      "Precision :  0.9207547169811321\n",
      "Recall :  0.9814963797264682\n",
      "F1 score :  0.9501557632398754\n",
      "Accuracy score :  0.963923337091319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tonyr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\scipy\\optimize\\_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\tonyr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " logistic regression\n",
      "Confusion matrics :  [[2144  161]\n",
      " [  26 1217]]\n",
      "Precision :  0.8831640058055152\n",
      "Recall :  0.9790828640386162\n",
      "F1 score :  0.9286531858069439\n",
      "Accuracy score :  0.9472942502818489\n",
      "\n",
      "\n",
      " mlp\n",
      "Confusion matrics :  [[2198  107]\n",
      " [  16 1227]]\n",
      "Precision :  0.9197901049475262\n",
      "Recall :  0.9871279163314561\n",
      "F1 score :  0.9522700814901048\n",
      "Accuracy score :  0.9653325817361894\n"
     ]
    }
   ],
   "source": [
    "for classifier_name, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    display_classifier_metrics(classifier_name, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "The result of the prediction using various learning algorithms shows that SVC has the least accuracy and F1 score while all the other algorithms perform well in classifying spam emails."
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "version": 1
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
